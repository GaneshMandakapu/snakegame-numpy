{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A2C RL Training in  multiAgent  Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLAYING  . . . TIME = 29 s\n",
      "PLAYER :  0\n",
      "|. 0 . . .|\n",
      "|. . . x .|\n",
      "|. . . . .|\n",
      "|. . . . .|\n",
      "|. . . . .|\n",
      "PLAYER :  1\n",
      "|. . . . .|\n",
      "|. . . . .|\n",
      "|. . . x .|\n",
      "|. . . . 0|\n",
      "|. . . . .|\n",
      "PLAYER :  2\n",
      "|. . x . .|\n",
      "|. . . . .|\n",
      "|. . . . .|\n",
      "|. . . . .|\n",
      "|. . . . 0|\n"
     ]
    }
   ],
   "source": [
    "import SnakeTrainer;\n",
    "import tensorflow as tf;\n",
    "from IPython.display import clear_output\n",
    "from time import sleep;\n",
    "\n",
    "runner = SnakeTrainer.SnakeRunner()\n",
    "runner.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Training MultiAgent MultiSnake Cooperative Environment\n",
    "In this case you will be able to observe multiple snakes fighting for the same resource in the same environment. This is an interesting case to try out, because they have to learn best stratagy to maximize the reward. Which means, ideally after extensive training, the far snake should pave the way for close by snakes (in order to maximize average reward)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLAYING  . . . TIME = 29 s\n",
      "PLAYER :  0\n",
      "|. . . . x|\n",
      "|. . . . 0|\n",
      "|. . . . .|\n",
      "|. . . 2 .|\n",
      "|. 1 . . .|\n",
      "PLAYER :  1\n",
      "|. . . . .|\n",
      "|. . . . .|\n",
      "|2 . . . .|\n",
      "|1 o . . .|\n",
      "|. 0 . x .|\n",
      "PLAYER :  2\n",
      "|. . . . .|\n",
      "|. 2 . . .|\n",
      "|. 1 0 . .|\n",
      "|. . . . .|\n",
      "|. . x . .|\n"
     ]
    }
   ],
   "source": [
    "import SnakeTrainer;\n",
    "import tensorflow as tf;\n",
    "from IPython.display import clear_output\n",
    "from time import sleep;\n",
    "\n",
    "runner = SnakeTrainer.SnakeRunner(n_envs=10,n_snakes=3)\n",
    "runner.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
